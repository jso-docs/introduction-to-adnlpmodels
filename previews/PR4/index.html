<!doctype html> <html lang=en  class=has-navbar-fixed-top > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/previews/PR4/libs/highlight/github.min.css"> <link rel=stylesheet  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//css/styles.css"> <style> html {font-size: 17px;} .franklin-content {position: relative; padding-left: 8%; padding-right: 5%; line-height: 1.35em;} @media (min-width: 940px) { .franklin-content {width: 100%; margin-left: auto; margin-right: auto;} } @media (max-width: 768px) { .franklin-content {padding-left: 6%; padding-right: 6%;} } </style> <link rel=icon  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//assets/favicon.png"> <title>Template</title> <script src="/previews/PR4/libs/highlight/highlight.pack.js"></script> <script src="https://unpkg.com/clipboard@2/dist/clipboard.min.js"></script> <script type=module  src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script> <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script> <script> hljs.getLanguage('julia').keywords.custom = 'obj grad hess AbstractNLPModel'; </script> <nav class="navbar is-primary is-fixed-top" role=navigation  aria-label="main navigation"> <div class=navbar-brand > <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4/"> <img src="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//assets/jso.png"> </a> <a role=button  class=navbar-burger  aria-label=menu  aria-expanded=false  data-target=navbarBasicExample > <span aria-hidden=true ></span> <span aria-hidden=true ></span> <span aria-hidden=true ></span> </a> </div> <div id=navbarBasicExample  class=navbar-menu > <div class=navbar-start > <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//"> Home </a> <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//news-and-blogposts/"> News and Blogposts </a> <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//tutorials/"> Tutorials </a> <div class="navbar-item has-dropdown is-hoverable"> <a class=navbar-link  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//ecosystems/index.html"> Ecosystems </a> <div class=navbar-dropdown > <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//ecosystems/linear-algebra/"> Linear Algebra </a> <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//ecosystems/models/"> Models </a> <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//ecosystems/solvers/"> Solvers </a> </div> </div> <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//references/"> References </a> <a class=navbar-item  href="https://introduction-to-adnlpmodels.netlify.app/previews/PR4//contributing/"> Contributing </a> </div> <div class=navbar-end > <div class=navbar-item > </div> </div> </div> </nav> <section class=section > <div class=container > <div class=content ><div class=franklin-content ><h1 id=title ><a href="#title" class=header-anchor >Template</a></h1></p> <div class=author >by AUTHORS</div> <p><a href="https://juliasmoothoptimizers.github.io/ADNLPModels.jl/stable/"><img class=badge  src="https://img.shields.io/badge/ADNLPModels-0.3.3-hsl(9,100%25,30%25)?style=flat-square&labelColor=hsl(9,30%25,30%25)"></a> <img class=badge  src="https://img.shields.io/badge/LinearAlgebra-nothing-666?style=flat-square&labelColor=999"> <a href="https://juliasmoothoptimizers.github.io/NLPModels.jl/stable/"><img class=badge  src="https://img.shields.io/badge/NLPModels-0.18.5-hsl(175,100%25,30%25)?style=flat-square&labelColor=hsl(175,30%25,30%25)"></a> <pre><code class=language-julia >Pages &#61; &#91;&quot;tutorial.md&quot;&#93;</code></pre><pre><code class="plaintext code-output">1-element Vector{String}:
 "tutorial.md"</code></pre> <h2 id=adnlpmodel_tutorial ><a href="#adnlpmodel_tutorial" class=header-anchor >ADNLPModel Tutorial</a></h2> <p>ADNLPModel is simple to use and is useful for classrooms. It only needs the objective function <code>f</code> and a starting point <code>x^0</code> to be well-defined. For constrained problems, you&#39;ll also need the constraints function <code>c</code>, and the constraints vectors <code>c_L</code> and <code>c_U</code>, such that <code>c_L \leq c&#40;x&#41; \leq c_U</code>. Equality constraints will be automatically identified as those indices <code>i</code> for which <code>c_&#123;L_i&#125; &#61; c_&#123;U_i&#125;</code>.</p> <p>Let&#39;s define the famous Rosenbrock function</p> <pre><code class=language-julia >f&#40;x&#41; &#61; &#40;x_1 - 1&#41;^2 &#43; 100&#40;x_2 - x_1^2&#41;^2,</code></pre><pre><code class="plaintext code-output">syntax: incomplete: premature end of input
</code></pre> <p>with starting point <code>x^0 &#61; &#40;-1.2,1.0&#41;</code>.</p> <pre><code class=language-julia >using ADNLPModels

nlp &#61; ADNLPModel&#40;x-&gt;&#40;x&#91;1&#93; - 1.0&#41;^2 &#43; 100*&#40;x&#91;2&#93; - x&#91;1&#93;^2&#41;^2 , &#91;-1.2; 1.0&#93;&#41;</code></pre><pre><code class="plaintext code-output">ADNLPModel - Model with automatic differentiation backend ADNLPModels.ForwardDiffAD{ForwardDiff.GradientConfig{ForwardDiff.Tag{var"#1#2", Float64}, Float64, 2, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var"#1#2", Float64}, Float64, 2}}}}(3, 0, ForwardDiff.GradientConfig{ForwardDiff.Tag{var"#1#2", Float64}, Float64, 2, Vector{ForwardDiff.Dual{ForwardDiff.Tag{var"#1#2", Float64}, Float64, 2}}}((Partials(1.0, 0.0), Partials(0.0, 1.0)), ForwardDiff.Dual{ForwardDiff.Tag{var"#1#2", Float64}, Float64, 2}[Dual{ForwardDiff.Tag{var"#1#2", Float64}}(0.0,6.9087909189488e-310,6.90879091030145e-310), Dual{ForwardDiff.Tag{var"#1#2", Float64}}(0.0,6.9087909189488e-310,6.90879178332177e-310)]))
  Problem name: Generic
   All variables: ████████████████████ 2      All constraints: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
            free: ████████████████████ 2                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
            nnzh: (  0.00% sparsity)   3               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
                                                    nonlinear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
                                                         nnzj: (------% sparsity)         

  Counters:
             obj: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 grad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 cons: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0           jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
</code></pre> <p>This is enough to define the model. Let&#39;s get the objective function value at <code>x^0</code>, using only <code>nlp</code>.</p> <pre><code class=language-julia >using NLPModels # To access the API

fx &#61; obj&#40;nlp, nlp.meta.x0&#41;
println&#40;&quot;fx &#61; &#36;fx&quot;&#41;</code></pre><pre><code class="plaintext code-output">fx = 24.199999999999996
</code></pre> <p>Done. Let&#39;s try the gradient and Hessian.</p> <pre><code class=language-julia >gx &#61; grad&#40;nlp, nlp.meta.x0&#41;
Hx &#61; hess&#40;nlp, nlp.meta.x0&#41;
println&#40;&quot;gx &#61; &#36;gx&quot;&#41;
println&#40;&quot;Hx &#61; &#36;Hx&quot;&#41;</code></pre><pre><code class="plaintext code-output">gx = [-215.59999999999997, -87.99999999999999]
Hx = [1330.0 480.0; 480.0 200.0]
</code></pre> <p>Notice that the Hessian is <em>dense</em>. This is a current limitation of this model. It doesn&#39;t return sparse matrices, so use it with care.</p> <p>Let&#39;s do something a little more complex here, defining a function to try to solve this problem through steepest descent method with Armijo search. Namely, the method</p> <ol> <li><p>Given <code>x^0</code>, <code>\varepsilon &gt; 0</code>, and <code>\eta \in &#40;0,1&#41;</code>. Set <code>k &#61; 0</code>;</p> <li><p>If <code>\Vert \nabla f&#40;x^k&#41; \Vert &lt; \varepsilon</code> STOP with <code>x^* &#61; x^k</code>;</p> <li><p>Compute <code>d^k &#61; -\nabla f&#40;x^k&#41;</code>;</p> <li><p>Compute <code>\alpha_k \in &#40;0,1&#93;</code> such that <code>f&#40;x^k &#43; \alpha_kd^k&#41; &lt; f&#40;x^k&#41; &#43; \alpha_k\eta \nabla f&#40;x^k&#41;^Td^k</code></p> <li><p>Define <code>x^&#123;k&#43;1&#125; &#61; x^k &#43; \alpha_kx^k</code></p> <li><p>Update <code>k &#61; k &#43; 1</code> and go to step 2.</p> </ol> <pre><code class=language-julia >using LinearAlgebra

function steepest&#40;nlp; itmax&#61;100000, eta&#61;1e-4, eps&#61;1e-6, sigma&#61;0.66&#41;
  x &#61; nlp.meta.x0
  fx &#61; obj&#40;nlp, x&#41;
  ∇fx &#61; grad&#40;nlp, x&#41;
  slope &#61; dot&#40;∇fx, ∇fx&#41;
  ∇f_norm &#61; sqrt&#40;slope&#41;
  iter &#61; 0
  while ∇f_norm &gt; eps &amp;&amp; iter &lt; itmax
    t &#61; 1.0
    x_trial &#61; x - t * ∇fx
    f_trial &#61; obj&#40;nlp, x_trial&#41;
    while f_trial &gt; fx - eta * t * slope
      t *&#61; sigma
      x_trial &#61; x - t * ∇fx
      f_trial &#61; obj&#40;nlp, x_trial&#41;
    end
    x &#61; x_trial
    fx &#61; f_trial
    ∇fx &#61; grad&#40;nlp, x&#41;
    slope &#61; dot&#40;∇fx, ∇fx&#41;
    ∇f_norm &#61; sqrt&#40;slope&#41;
    iter &#43;&#61; 1
  end
  optimal &#61; ∇f_norm &lt;&#61; eps
  return x, fx, ∇f_norm, optimal, iter
end

x, fx, ngx, optimal, iter &#61; steepest&#40;nlp&#41;
println&#40;&quot;x &#61; &#36;x&quot;&#41;
println&#40;&quot;fx &#61; &#36;fx&quot;&#41;
println&#40;&quot;ngx &#61; &#36;ngx&quot;&#41;
println&#40;&quot;optimal &#61; &#36;optimal&quot;&#41;
println&#40;&quot;iter &#61; &#36;iter&quot;&#41;</code></pre><pre><code class="plaintext code-output">x = [1.0000006499501406, 1.0000013043156974]
fx = 4.2438440239813445e-13
ngx = 9.984661274466946e-7
optimal = true
iter = 17962
</code></pre> <p>Maybe this code is too complicated? If you&#39;re in a class you just want to show a Newton step.</p> <pre><code class=language-julia >g&#40;x&#41; &#61; grad&#40;nlp, x&#41;
H&#40;x&#41; &#61; hess&#40;nlp, x&#41;
x &#61; nlp.meta.x0
d &#61; -H&#40;x&#41;\g&#40;x&#41;</code></pre><pre><code class="plaintext code-output">2-element Vector{Float64}:
 0.0247191011235955
 0.38067415730337073</code></pre> <p>or a few</p> <pre><code class=language-julia >for i &#61; 1:5
  global x
  x &#61; x - H&#40;x&#41;\g&#40;x&#41;
  println&#40;&quot;x &#61; &#36;x&quot;&#41;
end</code></pre><pre><code class="plaintext code-output">x = [-1.1752808988764045, 1.3806741573033707]
x = [0.763114871176314, -3.1750338547478294]
x = [0.7634296788839187, 0.5828247754969103]
x = [0.9999953110849887, 0.9440273238532714]
x = [0.9999956956536669, 0.9999913913257132]
</code></pre> <p>Also, notice how we can reuse the method.</p> <pre><code class=language-julia >f&#40;x&#41; &#61; &#40;x&#91;1&#93;^2 &#43; x&#91;2&#93;^2 - 5&#41;^2 &#43; &#40;x&#91;1&#93;*x&#91;2&#93; - 2&#41;^2
x0 &#61; &#91;3.0; 2.0&#93;
nlp &#61; ADNLPModel&#40;f, x0&#41;

x, fx, ngx, optimal, iter &#61; steepest&#40;nlp&#41;</code></pre><pre><code class="plaintext code-output">([1.9999999068493834, 1.000000113517522], 3.911490500207018e-14, 8.979870927068038e-7, true, 153)</code></pre>
<p>External models can be tested with <code>steepest</code> as well, as long as they implement <code>obj</code> and <code>grad</code>.</p>
<p>For constrained minimization, you need the constraints vector and bounds too. Bounds on the variables can be passed through a new vector.</p>
<pre><code class=language-julia >f&#40;x&#41; &#61; &#40;x&#91;1&#93; - 1.0&#41;^2 &#43; 100*&#40;x&#91;2&#93; - x&#91;1&#93;^2&#41;^2
x0 &#61; &#91;-1.2; 1.0&#93;
lvar &#61; &#91;-Inf; 0.1&#93;
uvar &#61; &#91;0.5; 0.5&#93;
c&#40;x&#41; &#61; &#91;x&#91;1&#93; &#43; x&#91;2&#93; - 2; x&#91;1&#93;^2 &#43; x&#91;2&#93;^2&#93;
lcon &#61; &#91;0.0; -Inf&#93;
ucon &#61; &#91;Inf; 1.0&#93;
nlp &#61; ADNLPModel&#40;f, x0, lvar, uvar, c, lcon, ucon&#41;

println&#40;&quot;cx &#61; &#36;&#40;cons&#40;nlp, nlp.meta.x0&#41;&#41;&quot;&#41;
println&#40;&quot;Jx &#61; &#36;&#40;jac&#40;nlp, nlp.meta.x0&#41;&#41;&quot;&#41;</code></pre><pre><code class="plaintext code-output">cx = [-2.2, 2.44]
Jx = [1.0 1.0; -2.4 2.0]
</code></pre>
<h2 id=adnlsmodel_tutorial ><a href="#adnlsmodel_tutorial" class=header-anchor >ADNLSModel tutorial</a></h2>
<p>In addition to the general nonlinear model, we can define the residual function for a nonlinear least-squares problem. In other words, the objective function of the problem is of the form <code>f&#40;x&#41; &#61; \tfrac&#123;1&#125;&#123;2&#125;\|F&#40;x&#41;\|^2</code>, and we can define the function <code>F</code> and its derivatives.</p>
<p>A simple way to define an NLS problem is with <code>ADNLSModel</code>, which uses automatic differentiation.</p>
<pre><code class=language-julia >F&#40;x&#41; &#61; &#91;x&#91;1&#93; - 1.0; 10 * &#40;x&#91;2&#93; - x&#91;1&#93;^2&#41;&#93;
x0 &#61; &#91;-1.2; 1.0&#93;
nls &#61; ADNLSModel&#40;F, x0, 2&#41; # 2 nonlinear equations

residual&#40;nls, x0&#41;

jac_residual&#40;nls, x0&#41;
#&#61;
&#61;#</code></pre><pre><code class="plaintext code-output">2×2 Matrix{Float64}:
  1.0   0.0
 24.0  10.0</code></pre>

</div>
    </div>  
    </div>  
    </div>  
  </section>  

    
    
        
<script>hljs.initHighlightingOnLoad(); hljs.configure({ tabReplace: '    ' });</script>


<script>
  (function () {

    // Get the elements.
    // - the 'pre' element.
    // - the 'div' with the 'paste-content' id.

    var pre = document.getElementsByTagName('pre');

    // Add a copy button in the 'pre' element with className language-julia

    for (var i = 0; i < pre.length; i++) {
      var isLanguage = pre[i].children[0].className.indexOf('language-julia');

      if (isLanguage === 0) {
        var ion_icon = document.createElement('ion-icon');
        ion_icon.name = 'copy';

        var icon = document.createElement('span');
        icon.className = 'icon has-text-primary';
        icon.appendChild(ion_icon);

        var button = document.createElement('button');
        button.className = 'button copy-button is-light is-primary';
        button.appendChild(icon);

        pre[i].appendChild(button);
      }
    };

    // Run Clipboard

    var copyCode = new ClipboardJS('.copy-button', {
      target: function (trigger) {
        return trigger.previousElementSibling;
      }
    });

    copyCode.on('success', function (event) {
      event.clearSelection();
      var btn = event.trigger;
      var old_button_class = btn.className;
      var old_icon_class = btn.children[0].className;
      btn.className = 'button copy-button is-primary';
      btn.children[0].className = 'icon has-text-white';
      window.setTimeout(function () {
        event.trigger.className = old_button_class;
        event.trigger.children[0].className = old_icon_class;
      }, 1000);

    });

  })();
</script>
    
    <footer class=footer >
      <div class="content has-text-centered is-small">
        &copy; Abel Soares Siqueira. <br>
        Last modified: June 25, 2022.<br>
        <a class=link  href="https://github.com/JuliaSmoothOptimizers/">JSO at GitHub</a>
      </div>
    </footer>